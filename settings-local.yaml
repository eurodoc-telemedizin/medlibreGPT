# poetry install --extras "ui llms-llama-cpp vector-stores-qdrant embeddings-huggingface"
server:
  env_name: ${APP_ENV:local}

llm:
  mode: llamacpp
  # Should be matching the selected model
  max_new_tokens: 4096
  context_window: 8000
  tokenizer: unsloth/medgemma-27b-text-it
  prompt_style: "chatml"

llamacpp:
  llm_hf_repo_id: unsloth/medgemma-27b-text-it-GGUF
  llm_hf_model_file: medgemma-27b-text-it.Q4_K_S.gguf
  temperature: 0.7
  top_p: 0.95
  repeat_penalty: 1.1
  n_threads: 12        # Adjust based on your CPU
  n_gpu_layers: 0     # Adjust based on your available GPU VRAM; set to 0 if CPU-only

embedding:
  mode: huggingface

huggingface:
  embedding_hf_model_name: nomic-ai/nomic-embed-text-v1.5

vectorstore:
  database: qdrant

qdrant:
  path: local_data/private_gpt/qdrant
